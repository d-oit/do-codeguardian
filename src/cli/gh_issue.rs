use crate::cli::{GhIssueArgs, GhMode};
use crate::github_api::GitHubApiClient;
use crate::types::AnalysisResults;
use anyhow::{anyhow, Result};
use std::process::Command;
use tokio::fs;

pub async fn run(args: GhIssueArgs) -> Result<()> {
    // Load results from JSON file
    let json_content = fs::read_to_string(&args.from).await?;
    let results: AnalysisResults = serde_json::from_str(&json_content)?;

    create_or_update_issue(&results, &args).await
}

pub async fn create_or_update_issue(results: &AnalysisResults, args: &GhIssueArgs) -> Result<()> {
    // Generate issue title
    let title = generate_issue_title(&args.title, &args.repo)?;

    // Generate issue body
    let body = generate_issue_body(results, &args.mode, args).await?;

    if args.dry_run {
        println!("DRY RUN: Would create/update GitHub issue");
        println!("Title: {}", title);
        println!("Repository: {}", args.repo);
        println!("Labels: {}", args.labels);
        println!("Body length: {} characters", body.len());
        return Ok(());
    }

    // Initialize GitHub API client with rate limiting
    let mut github_client = GitHubApiClient::new();

    // Handle different scan types with appropriate issue management
    let issue_strategy = determine_issue_strategy(&title, &args.labels);

    match issue_strategy {
        IssueStrategy::UpdateExisting => {
            handle_update_existing_issue(&mut github_client, &title, &body, args).await?;
        }
        IssueStrategy::CloseOldCreateNew => {
            handle_close_old_create_new(&mut github_client, &title, &body, args).await?;
        }
        IssueStrategy::CreateIfNotExists => {
            handle_create_if_not_exists(&mut github_client, &title, &body, args).await?;
        }
    }

    Ok(())
}

#[derive(Debug)]
enum IssueStrategy {
    UpdateExisting,    // For PR scans - update the same issue
    CloseOldCreateNew, // For push to main - close old, create new
    CreateIfNotExists, // For scheduled scans - create if none exists
}

fn determine_issue_strategy(title: &str, _labels: &str) -> IssueStrategy {
    if title.contains("PR #") {
        // PR scans should update the same issue
        IssueStrategy::UpdateExisting
    } else if title.contains("Push to main") || title.contains("Push to master") {
        // Main branch pushes should close old issues and create new ones
        IssueStrategy::CloseOldCreateNew
    } else if title.contains("Scheduled Scan") {
        // Scheduled scans should create if not exists
        IssueStrategy::CreateIfNotExists
    } else {
        // Default behavior
        IssueStrategy::UpdateExisting
    }
}

async fn handle_update_existing_issue(
    github_client: &mut GitHubApiClient,
    title: &str,
    body: &str,
    args: &GhIssueArgs,
) -> Result<()> {
    // Write body to temporary file
    let temp_file = "tmp_rovodev_issue_body.md";
    fs::write(temp_file, body).await?;

    // Check for existing issue (idempotency)
    let existing_issue = github_client.find_existing_issue(title, &args.repo).await?;

    // Create or update issue with rate limiting
    if let Some(issue_number) = existing_issue {
        github_client
            .update_issue(issue_number, temp_file, &args.labels, &args.repo)
            .await?;
        println!("‚úÖ Updated existing issue #{}", issue_number);
    } else {
        let issue_number = github_client
            .create_issue(title, temp_file, &args.labels, &args.repo)
            .await?;
        println!("‚úÖ Created new issue #{}", issue_number);
    }

    // Clean up temp file
    fs::remove_file(temp_file).await.ok();
    Ok(())
}

async fn handle_close_old_create_new(
    github_client: &mut GitHubApiClient,
    title: &str,
    body: &str,
    args: &GhIssueArgs,
) -> Result<()> {
    // First, close any existing CodeGuardian issues for this branch
    if let Err(e) = close_existing_branch_issues(github_client, title, &args.repo).await {
        eprintln!("‚ö†Ô∏è  Warning: Failed to close existing issues: {}", e);
    }

    // Write body to temporary file
    let temp_file = "tmp_rovodev_issue_body.md";
    fs::write(temp_file, body).await?;

    // Create new issue
    let issue_number = github_client
        .create_issue(title, temp_file, &args.labels, &args.repo)
        .await?;
    println!(
        "‚úÖ Created new issue #{} (closed previous issues)",
        issue_number
    );

    // Clean up temp file
    fs::remove_file(temp_file).await.ok();
    Ok(())
}

async fn handle_create_if_not_exists(
    github_client: &mut GitHubApiClient,
    title: &str,
    body: &str,
    args: &GhIssueArgs,
) -> Result<()> {
    // Check for existing issue
    let existing_issue = github_client.find_existing_issue(title, &args.repo).await?;

    if existing_issue.is_some() {
        println!("‚ÑπÔ∏è  Scheduled scan issue already exists, skipping creation");
        return Ok(());
    }

    // Write body to temporary file
    let temp_file = "tmp_rovodev_issue_body.md";
    fs::write(temp_file, body).await?;

    // Create new issue
    let issue_number = github_client
        .create_issue(title, temp_file, &args.labels, &args.repo)
        .await?;
    println!("‚úÖ Created new scheduled scan issue #{}", issue_number);

    // Clean up temp file
    fs::remove_file(temp_file).await.ok();
    Ok(())
}

async fn close_existing_branch_issues(
    github_client: &mut GitHubApiClient,
    title: &str,
    repo: &str,
) -> Result<()> {
    // Extract branch name from title
    let branch = if let Some(branch_start) = title.find("Push to ") {
        if let Some(branch_end) = title[branch_start + 8..].find(' ') {
            &title[branch_start + 8..branch_start + 8 + branch_end]
        } else {
            &title[branch_start + 8..]
        }
    } else {
        return Ok(()); // No branch info, skip closing
    };

    // Search for existing CodeGuardian issues for this branch
    let search_query = format!(
        "CodeGuardian \"Push to {}\" in:title label:codeguardian is:open",
        branch
    );
    let args = [
        "issue",
        "list",
        "--repo",
        repo,
        "--state",
        "open",
        "--search",
        &search_query,
        "--json",
        "number",
        "--limit",
        "5",
    ];

    let output = github_client.execute_gh_command(&args).await?;

    if output.trim().is_empty() || output.trim() == "null" {
        return Ok(());
    }

    // Parse and close issues
    if let Ok(issues) = serde_json::from_str::<Vec<serde_json::Value>>(&output) {
        for issue in issues {
            if let Some(number) = issue["number"].as_u64() {
                let close_args = [
                    "issue",
                    "close",
                    &number.to_string(),
                    "--repo",
                    repo,
                    "--comment",
                    "Closing previous scan results. New analysis available.",
                ];

                if let Err(e) = github_client.execute_gh_command(&close_args).await {
                    eprintln!("‚ö†Ô∏è  Warning: Failed to close issue #{}: {}", number, e);
                } else {
                    println!("üîí Closed previous issue #{}", number);
                }
            }
        }
    }

    Ok(())
}

#[allow(dead_code)]
async fn find_existing_issue(title: &str, repo: &str, dry_run: bool) -> Result<Option<u64>> {
    let search_query = format!("{} in:title", title);

    let cmd = format!(
        "gh issue list --repo {} --state open --search '{}' --json number,title -q '.[0].number'",
        repo, search_query
    );

    if dry_run {
        println!("DRY RUN: {}", cmd);
        return Ok(None);
    }

    let output = Command::new("sh").arg("-c").arg(&cmd).output()?;

    if output.status.success() {
        let stdout = String::from_utf8_lossy(&output.stdout).trim().to_string();
        if !stdout.is_empty() && stdout != "null" {
            return Ok(stdout.parse().ok());
        }
    }

    Ok(None)
}

#[allow(dead_code)]
async fn create_issue(
    title: &str,
    body: &str,
    labels: &str,
    repo: &str,
    dry_run: bool,
) -> Result<u64> {
    // Write body to temporary file to handle large content
    let temp_file = "tmp_rovodev_issue_body.md";
    fs::write(temp_file, body).await?;

    let cmd = format!(
        "gh issue create --repo {} --title '{}' --label '{}' --body-file {}",
        repo, title, labels, temp_file
    );

    if dry_run {
        println!("DRY RUN: {}", cmd);
        fs::remove_file(temp_file).await.ok();
        return Ok(0);
    }

    let output = Command::new("sh").arg("-c").arg(&cmd).output()?;

    // Clean up temp file
    fs::remove_file(temp_file).await.ok();

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(anyhow!("Failed to create GitHub issue: {}", stderr));
    }

    // Extract issue number from output (GitHub CLI returns URL)
    let stdout = String::from_utf8_lossy(&output.stdout);
    if let Some(issue_url) = stdout.lines().last() {
        if let Some(number_str) = issue_url.split('/').next_back() {
            return Ok(number_str.parse().unwrap_or(0));
        }
    }

    Ok(0)
}

#[allow(dead_code)]
async fn update_issue(
    issue_number: u64,
    body: &str,
    labels: &str,
    repo: &str,
    dry_run: bool,
) -> Result<()> {
    // Write body to temporary file
    let temp_file = "tmp_rovodev_issue_body.md";
    fs::write(temp_file, body).await?;

    let cmd = format!(
        "gh issue edit {} --repo {} --body-file {} --add-label '{}'",
        issue_number, repo, temp_file, labels
    );

    if dry_run {
        println!("DRY RUN: {}", cmd);
        fs::remove_file(temp_file).await.ok();
        return Ok(());
    }

    let output = Command::new("sh").arg("-c").arg(&cmd).output()?;

    // Clean up temp file
    fs::remove_file(temp_file).await.ok();

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(anyhow!("Failed to update GitHub issue: {}", stderr));
    }

    Ok(())
}

fn generate_issue_title(prefix: &str, _repo: &str) -> Result<String> {
    let mut title_parts = vec![prefix.trim_end_matches(": ").to_string()];

    // Determine context type and add appropriate identifier
    if let Ok(event_name) = std::env::var("GITHUB_EVENT_NAME") {
        match event_name.as_str() {
            "pull_request" => {
                // For PRs, use PR number and head commit
                if let Ok(pr_number) = std::env::var("GITHUB_PR_NUMBER") {
                    title_parts.push(format!("PR #{}", pr_number));

                    // Add head commit for uniqueness within PR
                    if let Ok(head_sha) = std::env::var("GITHUB_HEAD_SHA") {
                        let short_sha = &head_sha[..std::cmp::min(7, head_sha.len())];
                        title_parts.push(format!("({})", short_sha));
                    }
                } else {
                    // Fallback to current commit for PR context
                    if let Ok(output) = Command::new("git")
                        .args(["rev-parse", "--short", "HEAD"])
                        .output()
                    {
                        if output.status.success() {
                            let commit = String::from_utf8_lossy(&output.stdout).trim().to_string();
                            title_parts.push(format!("PR ({})", commit));
                        }
                    }
                }
            }
            "push" => {
                // For pushes, use branch and commit
                if let Ok(ref_name) = std::env::var("GITHUB_REF_NAME") {
                    title_parts.push(format!("Push to {}", ref_name));
                }
                if let Ok(sha) = std::env::var("GITHUB_SHA") {
                    let short_sha = &sha[..std::cmp::min(7, sha.len())];
                    title_parts.push(format!("({})", short_sha));
                }
            }
            "schedule" => {
                // For scheduled runs, use date and workflow
                let date = chrono::Utc::now().format("%Y-%m-%d");
                title_parts.push(format!("Scheduled Scan {}", date));

                if let Ok(workflow) = std::env::var("GITHUB_WORKFLOW") {
                    title_parts.push(format!("({})", workflow));
                }
            }
            _ => {
                // Generic event handling
                title_parts.push(format!("Event: {}", event_name));
                if let Ok(sha) = std::env::var("GITHUB_SHA") {
                    let short_sha = &sha[..std::cmp::min(7, sha.len())];
                    title_parts.push(format!("({})", short_sha));
                }
            }
        }
    } else {
        // Local execution fallback
        if let Ok(output) = Command::new("git")
            .args(["rev-parse", "--short", "HEAD"])
            .output()
        {
            if output.status.success() {
                let commit = String::from_utf8_lossy(&output.stdout).trim().to_string();
                title_parts.push(format!("Local ({})", commit));
            }
        } else {
            // Ultimate fallback to timestamp
            let timestamp = chrono::Utc::now().format("%Y%m%d-%H%M%S");
            title_parts.push(format!("Manual ({})", timestamp));
        }
    }

    Ok(title_parts.join(" "))
}

async fn generate_issue_body(
    results: &AnalysisResults,
    mode: &GhMode,
    args: &GhIssueArgs,
) -> Result<String> {
    let mut body = String::new();

    // Add summary from file if provided
    if let Some(summary_file) = &args.summary_from {
        if let Ok(summary_content) = fs::read_to_string(summary_file).await {
            body.push_str("## Summary\n\n");
            body.push_str(&summary_content);
            body.push_str("\n\n");
        }
    }

    // Add auto-generated summary if requested
    if let Some(provider) = &args.summary_auto {
        body.push_str("## ü§ñ AI Summary\n\n");
        body.push_str(&generate_ai_summary(results, provider)?);
        body.push_str("\n\n");
    }

    // Add analysis metadata
    body.push_str("## Analysis Details\n\n");
    body.push_str(&format!(
        "- **Generated:** {}\n",
        results.timestamp.format("%Y-%m-%d %H:%M:%S UTC")
    ));
    body.push_str(&format!(
        "- **Tool:** {} v{}\n",
        results.tool_metadata.name, results.tool_metadata.version
    ));
    body.push_str(&format!(
        "- **Files Scanned:** {}\n",
        results.summary.total_files_scanned
    ));
    body.push_str(&format!(
        "- **Total Findings:** {}\n",
        results.summary.total_findings
    ));
    body.push_str(&format!(
        "- **Duration:** {}ms\n\n",
        results.summary.scan_duration_ms
    ));

    // Generate findings based on mode
    match mode {
        GhMode::Checklist => {
            body.push_str(&generate_checklist_body(results, args)?);
        }
        GhMode::Simple => {
            body.push_str(&generate_simple_body(results, args)?);
        }
        GhMode::Children => {
            body.push_str(&generate_children_body(results, args)?);
        }
    }

    // Check if body is too large (GitHub limit ~65536 bytes)
    if body.len() > 60000 {
        body = truncate_body(body, results);
    }

    Ok(body)
}

fn generate_checklist_body(results: &AnalysisResults, args: &GhIssueArgs) -> Result<String> {
    let mut body = String::new();

    if results.findings.is_empty() {
        body.push_str(
            "## ‚úÖ No Issues Found\n\nGreat job! No issues were detected in the analyzed code.\n",
        );
        return Ok(body);
    }

    body.push_str("## üîç Findings Checklist\n\n");
    body.push_str("Check off items as they are resolved:\n\n");

    // Limit findings for readability
    let max_findings = args.summary_max_issues.min(results.findings.len());

    for finding in results.findings.iter().take(max_findings) {
        let emoji = match finding.severity {
            crate::types::Severity::Critical => "üî¥",
            crate::types::Severity::High => "üü†",
            crate::types::Severity::Medium => "üü°",
            crate::types::Severity::Low => "üîµ",
            crate::types::Severity::Info => "‚ÑπÔ∏è",
        };

        body.push_str(&format!(
            "- [ ] {} **{}** - `{}:{}` ({})\n",
            emoji,
            finding.message,
            finding.file.display(),
            finding.line,
            finding.id
        ));

        if let Some(description) = &finding.description {
            body.push_str(&format!("  > {}\n", description));
        }

        body.push('\n');
    }

    if results.findings.len() > max_findings {
        body.push_str(&format!(
            "\n*... and {} more findings. See full report for details.*\n",
            results.findings.len() - max_findings
        ));
    }

    Ok(body)
}

fn generate_simple_body(results: &AnalysisResults, _args: &GhIssueArgs) -> Result<String> {
    let mut body = String::new();

    if results.findings.is_empty() {
        body.push_str(
            "## ‚úÖ No Issues Found\n\nGreat job! No issues were detected in the analyzed code.\n",
        );
        return Ok(body);
    }

    // Use the markdown report generator
    let markdown_report = crate::cli::report::generate_markdown(results)?;
    body.push_str(&markdown_report);

    Ok(body)
}

fn generate_children_body(results: &AnalysisResults, args: &GhIssueArgs) -> Result<String> {
    let mut body = String::new();

    body.push_str("## üìã Analysis Overview\n\n");
    body.push_str("This is the main tracking issue for CodeGuardian analysis results.\n");
    body.push_str(
        "Individual findings will be created as separate child issues for better tracking.\n\n",
    );

    // Group findings by severity
    let mut critical = Vec::new();
    let mut high = Vec::new();
    let mut medium = Vec::new();
    let mut low = Vec::new();

    for finding in &results.findings {
        match finding.severity {
            crate::types::Severity::Critical => critical.push(finding),
            crate::types::Severity::High => high.push(finding),
            crate::types::Severity::Medium => medium.push(finding),
            crate::types::Severity::Low => low.push(finding),
            crate::types::Severity::Info => low.push(finding), // Treat info as low
        }
    }

    // Add summary by severity
    body.push_str("### üìä Findings Summary\n\n");
    if !critical.is_empty() {
        body.push_str(&format!("- üî¥ **Critical**: {} issues\n", critical.len()));
    }
    if !high.is_empty() {
        body.push_str(&format!("- üü† **High**: {} issues\n", high.len()));
    }
    if !medium.is_empty() {
        body.push_str(&format!("- üü° **Medium**: {} issues\n", medium.len()));
    }
    if !low.is_empty() {
        body.push_str(&format!("- üü¢ **Low/Info**: {} issues\n", low.len()));
    }

    body.push_str("\n### üîó Child Issues Strategy\n\n");

    // Create child issues for critical and high severity findings
    let high_priority_findings: Vec<_> = results
        .findings
        .iter()
        .filter(|f| {
            matches!(
                f.severity,
                crate::types::Severity::Critical | crate::types::Severity::High
            )
        })
        .collect();

    if !high_priority_findings.is_empty() {
        body.push_str("#### üö® High Priority (Separate Issues)\n\n");
        body.push_str("The following critical and high severity findings will be created as individual child issues:\n\n");

        for finding in &high_priority_findings {
            let child_title = format!(
                "[{}] {} - {}:{}",
                match finding.severity {
                    crate::types::Severity::Critical => "CRITICAL",
                    crate::types::Severity::High => "HIGH",
                    _ => "ISSUE",
                },
                finding.message.chars().take(50).collect::<String>(),
                finding.file.display(),
                finding.line
            );

            body.push_str(&format!(
                "- [ ] **{}** (ID: `{}`)\n",
                child_title, finding.id
            ));

            if args.dry_run {
                body.push_str("  - *Dry run: Would create child issue with GitHub CLI*\n");
            } else {
                body.push_str("  - *Child issue will be created automatically*\n");
            }

            if let Some(description) = &finding.description {
                body.push_str(&format!("  - Description: {}\n", description));
            }

            if let Some(suggestion) = &finding.suggestion {
                body.push_str(&format!("  - Suggested fix: {}\n", suggestion));
            }
        }
        body.push('\n');
    }

    // Add medium and low priority findings as a summary
    let lower_priority_findings: Vec<_> = results
        .findings
        .iter()
        .filter(|f| {
            matches!(
                f.severity,
                crate::types::Severity::Medium
                    | crate::types::Severity::Low
                    | crate::types::Severity::Info
            )
        })
        .collect();

    if !lower_priority_findings.is_empty() {
        body.push_str("#### üìù Lower Priority (Tracked Here)\n\n");
        body.push_str(
            "The following findings are tracked as checklist items in this main issue:\n\n",
        );

        let max_items = args.summary_max_issues.min(lower_priority_findings.len());
        for finding in lower_priority_findings.iter().take(max_items) {
            let severity_emoji = match finding.severity {
                crate::types::Severity::Medium => "üü°",
                crate::types::Severity::Low => "üü¢",
                crate::types::Severity::Info => "‚ÑπÔ∏è",
                _ => "‚ö™",
            };

            body.push_str(&format!(
                "- [ ] {} **{}** - `{}:{}` (ID: `{}`)\n",
                severity_emoji,
                finding.message,
                finding.file.display(),
                finding.line,
                finding.id
            ));

            if let Some(suggestion) = &finding.suggestion {
                body.push_str(&format!("  - *Suggestion: {}*\n", suggestion));
            }
        }

        if lower_priority_findings.len() > max_items {
            body.push_str(&format!(
                "\n*... and {} more findings (see full results.json)*\n",
                lower_priority_findings.len() - max_items
            ));
        }
    }

    body.push_str("\n### üõ†Ô∏è Implementation Guide\n\n");
    body.push_str("**Child Issue Creation:**\n");
    body.push_str("```bash\n");
    body.push_str("# Critical and High severity findings will be created as:\n");
    body.push_str("gh issue create --title \"[CRITICAL] Finding Title\" \\\n");
    body.push_str("  --body \"Detailed finding description with context\" \\\n");
    body.push_str("  --label \"codeguardian,critical,security\" \\\n");
    body.push_str("  --assignee @me\n");
    body.push_str("```\n\n");

    body.push_str("**Resolution Process:**\n");
    body.push_str("1. üî¥ Address Critical and High severity issues first (separate issues)\n");
    body.push_str("2. üü° Work through Medium priority items in this issue\n");
    body.push_str("3. üü¢ Address Low priority items as time permits\n");
    body.push_str("4. ‚úÖ Check off items as they are resolved\n");
    body.push_str("5. üîó Reference finding IDs in commit messages and PRs\n\n");

    body.push_str("**Finding ID Usage:**\n");
    body.push_str("```bash\n");
    body.push_str("git commit -m \"fix: resolve security issue (CodeGuardian: abc123def456)\"\n");
    body.push_str("```\n\n");

    Ok(body)
}

fn truncate_body(_body: String, results: &AnalysisResults) -> String {
    let mut truncated = String::new();

    truncated.push_str("## ‚ö†Ô∏è Report Truncated\n\n");
    truncated.push_str("This report was truncated due to size limits. ");
    truncated.push_str("See the full results.json artifact for complete details.\n\n");

    // Add summary only
    truncated.push_str("## Summary\n\n");
    truncated.push_str(&format!(
        "- **Total Findings:** {}\n",
        results.summary.total_findings
    ));
    truncated.push_str(&format!(
        "- **Files Scanned:** {}\n",
        results.summary.total_files_scanned
    ));

    // Add only critical and high severity findings
    let critical_high: Vec<_> = results
        .findings
        .iter()
        .filter(|f| {
            matches!(
                f.severity,
                crate::types::Severity::Critical | crate::types::Severity::High
            )
        })
        .take(10)
        .collect();

    if !critical_high.is_empty() {
        truncated.push_str("\n## üî¥ Critical & High Severity Issues\n\n");
        for finding in critical_high {
            truncated.push_str(&format!(
                "- **{}** - `{}:{}` ({})\n",
                finding.message,
                finding.file.display(),
                finding.line,
                finding.id
            ));
        }
    }

    truncated
}

fn generate_ai_summary(results: &AnalysisResults, provider: &str) -> Result<String> {
    let mut summary = String::new();

    // For now, provide a structured summary based on analysis
    // This can be enhanced with actual AI integration later

    match provider.to_lowercase().as_str() {
        "openai" | "claude" | "gemini" => {
            summary.push_str(&format!("*AI Provider: {}*\n\n", provider));
            summary.push_str("**Analysis Overview:**\n");

            // Generate intelligent summary based on findings
            let critical_count = results
                .findings
                .iter()
                .filter(|f| matches!(f.severity, crate::types::Severity::Critical))
                .count();
            let high_count = results
                .findings
                .iter()
                .filter(|f| matches!(f.severity, crate::types::Severity::High))
                .count();

            if critical_count > 0 {
                summary.push_str(&format!("üö® **Immediate Action Required**: {} critical security issues detected that need urgent attention.\n", critical_count));
            }

            if high_count > 0 {
                summary.push_str(&format!("‚ö†Ô∏è **High Priority**: {} high-severity issues found that should be addressed soon.\n", high_count));
            }

            // Analyze patterns in findings
            let mut analyzer_counts = std::collections::HashMap::new();
            for finding in &results.findings {
                *analyzer_counts.entry(&finding.analyzer).or_insert(0) += 1;
            }

            summary.push_str("\n**Key Areas of Concern:**\n");
            for (analyzer, count) in analyzer_counts.iter() {
                let description = match analyzer.as_str() {
                    "integrity" => "File integrity and corruption issues",
                    "lint_drift" => "Configuration drift and consistency problems",
                    "non_production" => "Non-production code and security vulnerabilities",
                    _ => "Code quality issues",
                };
                summary.push_str(&format!(
                    "- **{}**: {} issues - {}\n",
                    analyzer, count, description
                ));
            }

            // Generate recommendations
            summary.push_str("\n**Recommended Actions:**\n");
            if critical_count > 0 {
                summary.push_str(
                    "1. üî¥ **Immediate**: Address all critical security vulnerabilities\n",
                );
            }
            if high_count > 0 {
                summary.push_str("2. üü† **This Sprint**: Resolve high-priority issues\n");
            }
            summary.push_str("3. üü° **Next Sprint**: Work through medium-priority items\n");
            summary.push_str("4. üìä **Ongoing**: Monitor and prevent regression\n");

            // Risk assessment
            let total_high_risk = critical_count + high_count;
            summary.push_str("\n**Risk Assessment:**\n");
            if total_high_risk == 0 {
                summary
                    .push_str("‚úÖ **Low Risk**: No critical or high-severity issues detected.\n");
            } else if total_high_risk <= 3 {
                summary.push_str(
                    "üü° **Medium Risk**: Limited high-priority issues that can be managed.\n",
                );
            } else {
                summary.push_str("üî¥ **High Risk**: Multiple critical/high-severity issues require immediate attention.\n");
            }

            summary.push_str("\n*Note: This is a rule-based summary. For advanced AI analysis, integrate with your preferred AI provider.*\n");
        }
        _ => {
            summary.push_str(&format!("*Unknown AI provider: {}*\n\n", provider));
            summary.push_str("**Basic Summary:**\n");
            summary.push_str(&format!("- Total findings: {}\n", results.findings.len()));
            summary.push_str(&format!(
                "- Files scanned: {}\n",
                results.summary.total_files_scanned
            ));
            summary.push_str(&format!(
                "- Scan duration: {}ms\n",
                results.summary.scan_duration_ms
            ));
            summary.push_str("\n*To enable AI summarization, use: openai, claude, or gemini*\n");
        }
    }

    Ok(summary)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    #[test]
    fn test_generate_issue_title_pr_context() {
        // Set up PR environment
        env::set_var("GITHUB_EVENT_NAME", "pull_request");
        env::set_var("GITHUB_PR_NUMBER", "123");
        env::set_var("GITHUB_HEAD_SHA", "abcdef1234567890");

        let title = generate_issue_title("CodeGuardian: ", "owner/repo").unwrap();
        assert_eq!(title, "CodeGuardian PR #123 (abcdef1)");

        // Clean up
        env::remove_var("GITHUB_EVENT_NAME");
        env::remove_var("GITHUB_PR_NUMBER");
        env::remove_var("GITHUB_HEAD_SHA");
    }

    #[test]
    fn test_generate_issue_title_push_context() {
        // Set up push environment
        env::set_var("GITHUB_EVENT_NAME", "push");
        env::set_var("GITHUB_REF_NAME", "main");
        env::set_var("GITHUB_SHA", "abcdef1234567890");

        let title = generate_issue_title("CodeGuardian: ", "owner/repo").unwrap();
        assert_eq!(title, "CodeGuardian Push to main (abcdef1)");

        // Clean up
        env::remove_var("GITHUB_EVENT_NAME");
        env::remove_var("GITHUB_REF_NAME");
        env::remove_var("GITHUB_SHA");
    }

    #[test]
    fn test_generate_issue_title_scheduled_context() {
        // Set up scheduled environment
        env::set_var("GITHUB_EVENT_NAME", "schedule");
        env::set_var("GITHUB_WORKFLOW", "CodeGuardian CI");

        let title = generate_issue_title("CodeGuardian: ", "owner/repo").unwrap();
        assert!(title.starts_with("CodeGuardian Scheduled Scan"));
        assert!(title.contains("(CodeGuardian CI)"));

        // Clean up
        env::remove_var("GITHUB_EVENT_NAME");
        env::remove_var("GITHUB_WORKFLOW");
    }

    #[test]
    fn test_determine_issue_strategy() {
        // Test PR strategy
        let strategy =
            determine_issue_strategy("CodeGuardian PR #123 (abcdef1)", "codeguardian,pr-123");
        assert!(matches!(strategy, IssueStrategy::UpdateExisting));

        // Test main branch push strategy
        let strategy = determine_issue_strategy(
            "CodeGuardian Push to main (abcdef1)",
            "codeguardian,full-scan",
        );
        assert!(matches!(strategy, IssueStrategy::CloseOldCreateNew));

        // Test scheduled scan strategy
        let strategy = determine_issue_strategy(
            "CodeGuardian Scheduled Scan 2024-01-15",
            "codeguardian,scheduled",
        );
        assert!(matches!(strategy, IssueStrategy::CreateIfNotExists));
    }
}
